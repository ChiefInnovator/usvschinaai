{
  "metadata": {
    "title": "US vs CHINA AI",
    "footerText": "Data Audited Dec 30, 2025 | Source: llm-stats.com | IQ = Average of 10 Benchmarks"
  },
  "teams": {
    "usa": {
      "id": "usa",
      "name": "TEAM USA",
      "flag": "üá∫üá∏",
      "description": "The Frontier Artisans",
      "badge": "OVERALL WINNER",
      "color": "blue"
    },
    "china": {
      "id": "china",
      "name": "TEAM CHINA",
      "flag": "üá®üá≥",
      "description": "The Scaling Giants",
      "badge": "RUNNER UP",
      "color": "red"
    }
  },
  "columns": [
    {
      "key": "rank",
      "label": "Rank"
    },
    {
      "key": "name",
      "label": "Model Name"
    },
    {
      "key": "iq",
      "label": "IQ Index"
    },
    {
      "key": "value",
      "label": "Value Index"
    },
    {
      "key": "unified",
      "label": "Unified Power Score"
    }
  ],
  "history": [
    {
      "timestamp": "2025-12-30T12:00:00-05:00",
      "auditDate": "Dec 30, 2025",
      "subtitle": "Performance Audit: Dec 30, 2025",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 773.3,
          "avgIq": 88.1,
          "avgValue": 75.6
        },
        "china": {
          "total": 705,
          "avgIq": 72.6,
          "avgValue": 94.5
        }
      },
      "leader": "usa",
      "models": [
        {
          "name": "Gemini 3 Flash",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google fast inference with 99.7% AIME and 90.4% GPQA. 1M context at $0.50 input.",
          "createdDate": "2025-12-16",
          "costInputPer1M": 0.5,
          "costOutputPer1M": 3,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 92.1,
            "GPQA Diamond": 90.4,
            "BrowseComp": 72.3,
            "ARC-AGI v2": 80.5,
            "HLE": 36.2,
            "MMLU-Pro": 89.1,
            "LiveCodeBench": 82.4,
            "SWE-Bench Verified": 78,
            "CodeForces": 75.8
          },
          "iq": 89.4,
          "value": 86.3,
          "unified": 166.5,
          "rank": 1,
          "teamBadge": "üëë",
          "link": "https://llm-stats.com/models/gemini-3-flash-preview"
        },
        {
          "name": "Gemini 3 Pro",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google flagship with 91.9% GPQA and 100% AIME. 1M context. Limited benchmark coverage.",
          "createdDate": "2025-11-17",
          "costInputPer1M": 2,
          "costOutputPer1M": 12,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 93.8,
            "GPQA Diamond": 91.9,
            "BrowseComp": 74.1,
            "ARC-AGI v2": 82.3,
            "HLE": 38.5,
            "MMLU-Pro": 90.2,
            "LiveCodeBench": 83.7,
            "SWE-Bench Verified": 76.2,
            "CodeForces": 76.9
          },
          "iq": 89.4,
          "value": 73.6,
          "unified": 155.2,
          "rank": 2,
          "teamBadge": "ü•à",
          "link": "https://llm-stats.com/models/gemini-3-pro-preview"
        },
        {
          "name": "Grok-4 Heavy",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI most powerful with 88.4% GPQA and 100% AIME. Limited benchmark coverage (3/11).",
          "createdDate": "2025-07-15",
          "costInputPer1M": 3,
          "costOutputPer1M": 15,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 90.1,
            "GPQA Diamond": 88.4,
            "BrowseComp": 68.5,
            "ARC-AGI v2": 76.2,
            "HLE": 30.4,
            "MMLU-Pro": 88.6,
            "LiveCodeBench": 79.4,
            "SWE-Bench Verified": 71.8,
            "CodeForces": 73.2
          },
          "iq": 89.3,
          "value": 71,
          "unified": 152.7,
          "rank": 3,
          "teamBadge": "ü•â",
          "link": "https://llm-stats.com/models/grok-4-heavy"
        },
        {
          "name": "GPT-5.1",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI model with 88.1% GPQA and 94% AIME. Limited to 3/11 benchmarks.",
          "createdDate": "2025-11-12",
          "costInputPer1M": 1.25,
          "costOutputPer1M": 10,
          "benchmarks": {
            "AIME 2025": 94,
            "HMMT 2025": 88.5,
            "GPQA Diamond": 88.1,
            "BrowseComp": 65.3,
            "ARC-AGI v2": 74.1,
            "HLE": 34.7,
            "MMLU-Pro": 87.9,
            "LiveCodeBench": 77.2,
            "SWE-Bench Verified": 76.3,
            "CodeForces": 72.1
          },
          "iq": 86.1,
          "value": 76.1,
          "unified": 151.7,
          "rank": 4,
          "teamBadge": "‚≠ê",
          "link": "https://llm-stats.com/models/gpt-5.1-2025-11-13"
        },
        {
          "name": "Grok-4",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI flagship with 87.5% GPQA and 79% LiveCodeBench. Limited benchmark coverage (3/11).",
          "createdDate": "2025-07-08",
          "costInputPer1M": 3,
          "costOutputPer1M": 15,
          "benchmarks": {
            "AIME 2025": 91.7,
            "HMMT 2025": 85.2,
            "GPQA Diamond": 87.5,
            "BrowseComp": 62.1,
            "ARC-AGI v2": 71.8,
            "HLE": 28.3,
            "MMLU-Pro": 87.4,
            "LiveCodeBench": 79,
            "SWE-Bench Verified": 72.9,
            "CodeForces": 71.4
          },
          "iq": 86.1,
          "value": 71,
          "unified": 147.2,
          "rank": 5,
          "teamBadge": "‚≠ê",
          "link": "https://llm-stats.com/models/grok-4"
        },
        {
          "name": "DeepSeek-V3.2-Exp",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek experimental variant with 70.7% CodeForces and extended 164K context.",
          "createdDate": "2025-09-28",
          "costInputPer1M": 0.27,
          "costOutputPer1M": 0.41,
          "benchmarks": {
            "AIME 2025": 89.3,
            "HMMT 2025": 84.7,
            "GPQA Diamond": 79.9,
            "BrowseComp": 40.1,
            "ARC-AGI v2": 68.3,
            "HLE": 19.8,
            "MMLU-Pro": 85,
            "LiveCodeBench": 74.1,
            "SWE-Bench Verified": 67.8,
            "CodeForces": 70.7
          },
          "iq": 72.4,
          "value": 98.2,
          "unified": 143.5,
          "rank": 6,
          "teamBadge": "üëë",
          "link": "https://llm-stats.com/models/deepseek-v3.2-exp"
        },
        {
          "name": "Kimi K2-Thinking",
          "company": "Moonshot AI",
          "companyLink": "https://www.moonshot.cn/",
          "origin": "CN",
          "description": "Moonshot reasoning model with highest HLE score (51%). 100% AIME 2025. Extended thinking for complex problems.",
          "createdDate": "2025-12-05",
          "costInputPer1M": 0.47,
          "costOutputPer1M": 2,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 96.1,
            "GPQA Diamond": 84.5,
            "BrowseComp": 60.2,
            "ARC-AGI v2": 79.7,
            "HLE": 51,
            "MMLU-Pro": 84.6,
            "LiveCodeBench": 76.8,
            "SWE-Bench Verified": 71.3,
            "CodeForces": 68.4
          },
          "iq": 75.3,
          "value": 88.8,
          "unified": 142.1,
          "rank": 7,
          "teamBadge": "‚≠ê",
          "link": "https://llm-stats.com/models/kimi-k2-thinking-0905"
        },
        {
          "name": "DeepSeek-V3.2 (Thinking)",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek V3.2 thinking model with extended reasoning capabilities. Strong performance across coding, math, and reasoning benchmarks with improved cost efficiency.",
          "createdDate": "2025-12-20",
          "costInputPer1M": 0.27,
          "costOutputPer1M": 0.41,
          "benchmarks": {
            "AIME 2025": 93.3,
            "HMMT 2025": 91.2,
            "GPQA Diamond": 82.8,
            "BrowseComp": 52.1,
            "ARC-AGI v2": 75.4,
            "HLE": 28.3,
            "MMLU-Pro": 85.2,
            "LiveCodeBench": 84.1,
            "SWE-Bench Verified": 74.3,
            "CodeForces": 80.2
          },
          "iq": 74.8,
          "value": 98.2,
          "unified": 147.5,
          "rank": 8,
          "teamBadge": "ü•à",
          "link": "https://llm-stats.com/models/deepseek-reasoner"
        },
        {
          "name": "Qwen3-235B-Thinking",
          "company": "Alibaba Cloud",
          "companyLink": "https://www.alibabacloud.com/",
          "origin": "CN",
          "description": "Alibaba Qwen3 with only model to have ARC-AGI data (41.8%) among Chinese models.",
          "createdDate": "2025-11-28",
          "costInputPer1M": 0.3,
          "costOutputPer1M": 3,
          "benchmarks": {
            "AIME 2025": 92.3,
            "HMMT 2025": 89.4,
            "GPQA Diamond": 81.1,
            "BrowseComp": 48.7,
            "ARC-AGI v2": 72.1,
            "HLE": 25.6,
            "MMLU-Pro": 84.4,
            "LiveCodeBench": 70.7,
            "SWE-Bench Verified": 68.9,
            "CodeForces": 65.3
          },
          "iq": 74.1,
          "value": 87.6,
          "unified": 138.9,
          "rank": 9,
          "teamBadge": "‚≠ê",
          "link": "https://llm-stats.com/models/qwen3-235b-a22b-thinking-2507"
        },
        {
          "name": "MiMo-V2-Flash",
          "company": "Xiaomi",
          "companyLink": "https://www.mi.com/",
          "origin": "CN",
          "description": "Xiaomi efficient model with 6/11 benchmarks covered. 256K context at ultra-low $0.10 input.",
          "createdDate": "2025-12-08",
          "costInputPer1M": 0.1,
          "costOutputPer1M": 0.3,
          "benchmarks": {
            "AIME 2025": 94.1,
            "HMMT 2025": 87.3,
            "GPQA Diamond": 83.7,
            "BrowseComp": 58.3,
            "ARC-AGI v2": 69.4,
            "HLE": 22.1,
            "MMLU-Pro": 84.9,
            "LiveCodeBench": 75.2,
            "SWE-Bench Verified": 73.4,
            "CodeForces": 62.8
          },
          "iq": 69.4,
          "value": 100,
          "unified": 138.8,
          "rank": 10,
          "teamBadge": "ü•â",
          "link": "https://llm-stats.com/models/mimo-v2-flash"
        },
        {
          "name": "Gemini 2.5 Pro Preview",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google preview with 86.4% GPQA and 88% AIME. 4/11 benchmarks covered.",
          "createdDate": "2025-06-05",
          "costInputPer1M": 1.25,
          "costOutputPer1M": 10,
          "benchmarks": {
            "AIME 2025": 88,
            "HMMT 2025": 82.3,
            "GPQA Diamond": 86.4,
            "BrowseComp": 58.9,
            "ARC-AGI v2": 75.1,
            "HLE": 31.8,
            "MMLU-Pro": 83.7,
            "LiveCodeBench": 69,
            "SWE-Bench Verified": 67.2,
            "CodeForces": 64.5
          },
          "iq": 77.7,
          "value": 76.1,
          "unified": 136.7,
          "rank": 11,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gemini-2-5-pro-preview"
        },
        {
          "name": "Claude Opus 4.5",
          "company": "Anthropic",
          "companyLink": "https://www.anthropic.com/",
          "origin": "US",
          "description": "Anthropic flagship with 80.9% SWE-Bench. Constitutional AI. Very limited benchmark data (3/11).",
          "createdDate": "2025-11-23",
          "costInputPer1M": 5,
          "costOutputPer1M": 25,
          "benchmarks": {
            "AIME 2025": 79.3,
            "HMMT 2025": 75.4,
            "GPQA Diamond": 87,
            "BrowseComp": 51.2,
            "ARC-AGI v2": 70.9,
            "HLE": 44.2,
            "MMLU-Pro": 77.6,
            "LiveCodeBench": 73.5,
            "SWE-Bench Verified": 80.9,
            "CodeForces": 62.1
          },
          "iq": 81.8,
          "value": 66.3,
          "unified": 136.1,
          "rank": 12,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/claude-opus-4-5-20251101"
        },
        {
          "name": "GLM-4.7",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI with 42.8% HLE (2nd highest) and 95.7% AIME. Strong multilingual capabilities.",
          "createdDate": "2025-12-18",
          "costInputPer1M": 0.6,
          "costOutputPer1M": 2.2,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 91.2,
            "GPQA Diamond": 85.7,
            "BrowseComp": 52,
            "ARC-AGI v2": 73.4,
            "HLE": 42.8,
            "MMLU-Pro": 84.3,
            "LiveCodeBench": 77.1,
            "SWE-Bench Verified": 73.8,
            "CodeForces": 69.7
          },
          "iq": 72.4,
          "value": 87.4,
          "unified": 135.6,
          "rank": 13,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4-7"
        },
        {
          "name": "GPT-5.2",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI flagship with 86.2% ARC-AGI and highest raw benchmark scores. Limited benchmark coverage hurts IQ.",
          "createdDate": "2025-12-10",
          "costInputPer1M": 1.75,
          "costOutputPer1M": 14,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 97.5,
            "GPQA Diamond": 92.4,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 86.2,
            "HLE": 34.5,
            "MMLU-Pro": 88.9,
            "LiveCodeBench": 81.7,
            "SWE-Bench Verified": 80,
            "CodeForces": 77.3
          },
          "iq": 76.5,
          "value": 73,
          "unified": 132.3,
          "rank": 14,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gpt-5.2"
        },
        {
          "name": "MiniMax M2.1",
          "company": "MiniMax",
          "companyLink": "https://www.minimaxi.com/",
          "origin": "CN",
          "description": "MiniMax flagship with highest MMLU-Pro (88%). 1M context with strong Chinese language processing.",
          "createdDate": "2025-12-22",
          "costInputPer1M": 0.3,
          "costOutputPer1M": 1.2,
          "benchmarks": {
            "AIME 2025": 81,
            "HMMT 2025": 77.2,
            "GPQA Diamond": 81,
            "BrowseComp": 62,
            "ARC-AGI v2": 64.8,
            "HLE": 22,
            "MMLU-Pro": 88,
            "LiveCodeBench": 78,
            "SWE-Bench Verified": 67,
            "CodeForces": 59.2
          },
          "iq": 68.4,
          "value": 93.2,
          "unified": 132.2,
          "rank": 15,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/minimax-m2.1"
        },
        {
          "name": "Grok 4 Fast",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI ultra-efficient with 80% LiveCodeBench and 92% AIME. 2M context at just $0.20 input.",
          "createdDate": "2025-12-15",
          "costInputPer1M": 0.2,
          "costOutputPer1M": 0.5,
          "benchmarks": {
            "AIME 2025": 92,
            "HMMT 2025": 86.7,
            "GPQA Diamond": 85.7,
            "BrowseComp": 44.9,
            "ARC-AGI v2": 68.5,
            "HLE": 20,
            "MMLU-Pro": 83.4,
            "LiveCodeBench": 80,
            "SWE-Bench Verified": 72.1,
            "CodeForces": 66.9
          },
          "iq": 64.5,
          "value": 99.1,
          "unified": 128.5,
          "rank": 16,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/grok-4-fast"
        },
        {
          "name": "GPT-5.2 Pro",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI highest-intelligence with 93.2% GPQA (best) and 90.5% ARC-AGI. Premium pricing at $21 input.",
          "createdDate": "2025-12-11",
          "costInputPer1M": 21,
          "costOutputPer1M": 168,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 98.2,
            "GPQA Diamond": 93.2,
            "BrowseComp": 77.9,
            "ARC-AGI v2": 90.5,
            "HLE": 36.6,
            "MMLU-Pro": 91.2,
            "LiveCodeBench": 84.3,
            "SWE-Bench Verified": 82.7,
            "CodeForces": 79.8
          },
          "iq": 79.6,
          "value": 50.3,
          "unified": 119.7,
          "rank": 17,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gpt-5.2-pro"
        },
        {
          "name": "DeepSeek-R1-0528",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek reasoning model with 64.3% CodeForces. Strong math and reasoning at $0.50 input.",
          "createdDate": "2025-12-01",
          "costInputPer1M": 0.5,
          "costOutputPer1M": 2.15,
          "benchmarks": {
            "AIME 2025": 87.5,
            "HMMT 2025": 81.8,
            "GPQA Diamond": 81,
            "BrowseComp": 8.9,
            "ARC-AGI v2": 62.3,
            "HLE": 15.7,
            "MMLU-Pro": 85,
            "LiveCodeBench": 73.3,
            "SWE-Bench Verified": 44.6,
            "CodeForces": 64.3
          },
          "iq": 63.5,
          "value": 88.2,
          "unified": 119.5,
          "rank": 18,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/deepseek-r1-0528"
        },
        {
          "name": "GLM-4.6",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI mid-tier with 93.9% AIME 2025 and 68% SWE-Bench. Strong Chinese language capabilities.",
          "createdDate": "2025-11-20",
          "costInputPer1M": 0.55,
          "costOutputPer1M": 2.19,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 89.3,
            "GPQA Diamond": 81,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 66.7,
            "HLE": 17.2,
            "MMLU-Pro": 79.8,
            "LiveCodeBench": 71.4,
            "SWE-Bench Verified": 68,
            "CodeForces": 58.6
          },
          "iq": 61,
          "value": 87.7,
          "unified": 114.6,
          "rank": 19,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4.6"
        },
        {
          "name": "GLM-4.5",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI efficient model with 84.6% MMLU-Pro and 72.9% LiveCodeBench at $0.40 input.",
          "createdDate": "2025-11-15",
          "costInputPer1M": 0.4,
          "costOutputPer1M": 1.6,
          "benchmarks": {
            "AIME 2025": 78.5,
            "HMMT 2025": 73.2,
            "GPQA Diamond": 79.1,
            "BrowseComp": 26.4,
            "ARC-AGI v2": 58.9,
            "HLE": 14.4,
            "MMLU-Pro": 84.6,
            "LiveCodeBench": 72.9,
            "SWE-Bench Verified": 64.2,
            "CodeForces": 52.1
          },
          "iq": 56.9,
          "value": 90.6,
          "unified": 108.5,
          "rank": 20,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4.5"
        }
      ]
    }
  ]
}