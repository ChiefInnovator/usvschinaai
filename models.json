{
  "metadata": {
    "title": "US vs CHINA AI",
    "footerText": "Data Audited Dec 30, 2025 | Source: llm-stats.com | IQ = Average of 10 Benchmarks"
  },
  "teams": {
    "usa": {
      "id": "usa",
      "name": "TEAM USA",
      "flag": "\ud83c\uddfa\ud83c\uddf8",
      "description": "The Frontier Artisans",
      "badge": "OVERALL WINNER",
      "color": "blue"
    },
    "china": {
      "id": "china",
      "name": "TEAM CHINA",
      "flag": "\ud83c\udde8\ud83c\uddf3",
      "description": "The Scaling Giants",
      "badge": "RUNNER UP",
      "color": "red"
    }
  },
  "columns": [
    {
      "key": "rank",
      "label": "Rank"
    },
    {
      "key": "name",
      "label": "Model Name"
    },
    {
      "key": "iq",
      "label": "IQ Index"
    },
    {
      "key": "value",
      "label": "Value Index"
    },
    {
      "key": "unified",
      "label": "Unified Power Score"
    }
  ],
  "history": [
    {
      "timestamp": "2026-01-21T22:20:06+07:59",
      "teams": {
        "US": [],
        "CN": []
      }
    },
    {
      "timestamp": "2026-01-21T18:41:52+07:59",
      "teams": {
        "US": [
          {
            "model": "Claude Opus 4.5",
            "company": "",
            "link": "https://llm-stats.com/models/claude-opus-4-5-20251101",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 1.0,
            "avgIq": 0.1,
            "value": 0.0,
            "unified": 0.07,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 1.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Gemini 3 Pro",
            "company": "",
            "link": "https://llm-stats.com/models/gemini-3-pro-preview",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "GPT-5.2",
            "company": "",
            "link": "https://llm-stats.com/models/gpt-5.2-2025-12-11",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Gemini 3 Flash",
            "company": "",
            "link": "https://llm-stats.com/models/gemini-3-flash-preview",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Claude Opus 4",
            "company": "",
            "link": "https://llm-stats.com/models/claude-opus-4-20250514",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Claude Sonnet 4.5",
            "company": "",
            "link": "https://llm-stats.com/models/claude-sonnet-4-5-20250929",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Claude Opus 4.1",
            "company": "",
            "link": "https://llm-stats.com/models/claude-opus-4-1-20250805",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "GPT-5.1 Medium",
            "company": "",
            "link": "https://llm-stats.com/models/gpt-5.1-medium-2025-11-12",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Gemini 2.5 Pro",
            "company": "",
            "link": "https://llm-stats.com/models/gemini-2.5-pro",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Claude Sonnet 4",
            "company": "",
            "link": "https://llm-stats.com/models/claude-sonnet-4-20250514",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          }
        ],
        "CN": [
          {
            "model": "GLM-4.7",
            "company": "",
            "link": "https://llm-stats.com/models/glm-4.7",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 1.0,
            "avgIq": 0.1,
            "value": 0.0,
            "unified": 0.07,
            "AIME 2025": 1.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "GLM-4.6",
            "company": "",
            "link": "https://llm-stats.com/models/glm-4.6",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "MiniMax M2.1",
            "company": "",
            "link": "https://llm-stats.com/models/minimax-m2.1",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 1.0,
            "avgIq": 0.1,
            "value": 0.0,
            "unified": 0.07,
            "AIME 2025": 1.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "DeepSeek-V3.2-Speciale",
            "company": "",
            "link": "https://llm-stats.com/models/deepseek-v3.2-speciale",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "MiMo-V2-Flash",
            "company": "",
            "link": "https://llm-stats.com/models/mimo-v2-flash",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Kimi K2-Thinking-0905",
            "company": "",
            "link": "https://llm-stats.com/models/kimi-k2-thinking-0905",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "GLM-4.7-Flash",
            "company": "",
            "link": "https://llm-stats.com/models/glm-4.7-flash",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 1.0,
            "avgIq": 0.1,
            "value": 0.0,
            "unified": 0.07,
            "AIME 2025": 1.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "GLM-4.5",
            "company": "",
            "link": "https://llm-stats.com/models/glm-4.5",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "Kimi K2 0905",
            "company": "",
            "link": "https://llm-stats.com/models/kimi-k2-0905",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          {
            "model": "DeepSeek-V3.2 (Thinking)",
            "company": "",
            "link": "https://llm-stats.com/models/deepseek-reasoner",
            "created": "",
            "description": "",
            "costIn": 0.0,
            "costOut": 0.0,
            "total": 0.0,
            "avgIq": 0.0,
            "value": 0.0,
            "unified": 0.0,
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          }
        ]
      }
    },
    {
      "timestamp": "2026-01-21T18:24:43+08:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 0.2,
          "avgIq": 0.0,
          "avgValue": 100.0
        },
        "china": {
          "total": 0.0,
          "avgIq": 0.0,
          "avgValue": 100.0
        }
      },
      "leader": "usa",
      "models": [
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-5-20251101",
          "origin": "US",
          "description": "Premium model combining maximum intelligence with practical performance. Best model in the world for coding, agents, and computer use. Most robustly aligned model with best prompt injection resistance of any frontier model. Features extended thinking, 200K context window, 64K max output, and a new effort parameter for controlling reasoning depth. Pricing: $5/$25 per million tokens (input/output).",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 1.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.1,
          "value": 100.0,
          "unified": 0.2,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-3-pro-preview",
          "origin": "US",
          "description": "Gemini 3 Pro is the first model in the new Gemini 3 series. It is best for complex tasks that require broad world knowledge and advanced reasoning across modalities. Gemini 3 Pro uses dynamic thinking by default to reason through prompts, and features a 1 million-token input context window with 64k output tokens.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gpt-5.2-2025-12-11",
          "origin": "US",
          "description": "GPT\u20115.2 introduces substantial gains in professional knowledge work, outperforming experts on GDPval with 70.9% wins or ties, and setting new highs in coding (SWE\u2011Bench Pro 55.6%), science (GPQA Diamond ~92\u201393%), math (AIME 2025: 100%), long\u2011context accuracy up to 256k tokens, and reliable tool\u2011calling (Tau2 Telecom 98.7%). It rolls out as Instant, Thinking, and Pro\u2014faster, more structured, and less error\u2011prone\u2014priced at $1.75/1M input and $14/1M output tokens, with Pro variants supporting xhigh reasoning for top\u2011quality, end\u2011to\u2011end execution.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-3-flash-preview",
          "origin": "US",
          "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost. It combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost. Features a 1 million-token input context window and is optimized for agentic workflows, coding, and complex analysis.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-20250514",
          "origin": "US",
          "description": "Claude Opus 4 is Anthropic's most powerful model and the world's best coding model, part of the Claude 4 family. It delivers sustained performance on complex, long-running tasks and agent workflows. Opus 4 excels at coding, advanced reasoning, and can use tools (like web search) during extended thinking. It supports parallel tool execution and has improved memory capabilities.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-sonnet-4-5-20250929",
          "origin": "US",
          "description": "Claude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It\u2019s the best model at using computers. And it shows substantial gains in reasoning and math. Highest intelligence across most tasks with exceptional agent and coding capabilities.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-1-20250805",
          "origin": "US",
          "description": "Claude Opus 4.1 is a hybrid reasoning model that pushes the frontier for coding and AI agents, featuring a 200K context window. It delivers superior performance and precision for real-world coding and agentic tasks, handling complex multi-step problems with rigor and attention to detail. With extended thinking capabilities, it offers instant responses or extended step-by-step thinking visible through user-friendly summaries. It advances state-of-the-art coding performance to 74.5% on SWE-bench Verified, excels at agentic search and research, and produces human-quality content with exceptional writing abilities. It supports 32K output tokens and adapts to specific coding styles while delivering exceptional quality for extensive generation and refactoring projects.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.1 Medium",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gpt-5.1-medium-2025-11-12",
          "origin": "US",
          "description": "GPT-5.1 Medium balances reasoning depth with response speed, providing medium-effort thinking for moderately complex tasks. This variant offers more thorough analysis than instant responses while maintaining faster performance than high-effort reasoning.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 2.5 Pro",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-2.5-pro",
          "origin": "US",
          "description": "A highly capable AI model from Google, designed for the agentic era. Gemini 2.5 Pro performs well on common benchmarks with enhanced reasoning, multimodal capabilities (text, image, video, audio input), and a 1M token context window.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-sonnet-4-20250514",
          "origin": "US",
          "description": "Claude Sonnet 4, part of the Claude 4 family, is a significant upgrade to Claude Sonnet 3.7. It excels in coding (72.7% on SWE-bench) and reasoning, responding more precisely to instructions. Sonnet 4 offers an optimal mix of capability and practicality, with enhanced steerability, and supports extended thinking with tool use.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.7",
          "origin": "CN",
          "description": "GLM 4.7 is a coding\u2011centric model that thinks before acting, preserves its reasoning across turns, and lets you control thinking per request for speed or accuracy. It upgrades agentic workflows with stronger multi\u2011step tool use, better terminal and multilingual coding, and a noticeable jump in UI output quality for modern, clean webpages and slides. You can use it in popular coding agents, call it via the Z.ai API, and even run it locally with public weights on HuggingFace and ModelScope using vLLM or SGLang.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.6",
          "origin": "CN",
          "description": "GLM-4.6 is the latest version of Z.ai's flagship model, bringing significant improvements over GLM-4.5. Key features include: 200K token context window (expanded from 128K), superior coding performance with better real-world application in Claude Code/Cline/Roo Code/Kilo Code, advanced reasoning with tool use during inference, stronger agent capabilities, and refined writing aligned with human preferences. GLM-4.6 achieves competitive performance with DeepSeek-V3.2-Exp and Claude Sonnet 4, reaching near parity with Claude Sonnet 4 (48.6% win rate) on CC-Bench real-world coding tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "https://llm-stats.com/models/minimax-m2.1",
          "origin": "CN",
          "description": "MiniMax M2.1 is an enhanced large language model focused on multi-language programming and real-world complex tasks. It features exceptional capabilities across Rust, Java, Golang, C++, Kotlin, Objective-C, TypeScript, JavaScript and more, with industry-leading multilingual performance that outperforms Claude Sonnet 4.5 and approaches Claude Opus 4.5. M2.1 significantly strengthens native Android and iOS development, delivers enhanced design comprehension and aesthetic expression for web/app scenarios, and provides more concise responses with improved speed and reduced token consumption. It excels across various coding agent frameworks including Claude Code, Droid (Factory AI), Cline, Kilo Code, Roo Code, and BlackBox.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2-Speciale",
          "company": "",
          "companyLink": "https://llm-stats.com/models/deepseek-v3.2-speciale",
          "origin": "CN",
          "description": "DeepSeek-V3.2-Speciale is a specialized variant of DeepSeek-V3.2, optimized for enhanced performance on specific tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "MiMo-V2-Flash",
          "company": "",
          "companyLink": "https://llm-stats.com/models/mimo-v2-flash",
          "origin": "CN",
          "description": "MiMo-V2-Flash is a powerful, efficient, and ultra-fast foundation language model that excels in reasoning, coding, and agentic scenarios. It is a Mixture-of-Experts model with 309B total parameters and 15B active parameters, featuring a hybrid attention architecture with sliding-window and full attention (5:1 ratio, 128-token window). Delivers 150 tokens/sec inference with 256k context window.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2-Thinking-0905",
          "company": "",
          "companyLink": "https://llm-stats.com/models/kimi-k2-thinking-0905",
          "origin": "CN",
          "description": "Kimi K2 Thinking is the latest, most capable version of open-source thinking model. Starting with Kimi K2, it is built as a thinking agent that reasons step-by-step while dynamically invoking tools. It sets a new state-of-the-art on Humanity's Last Exam (HLE), BrowseComp, and other benchmarks by dramatically scaling multi-step reasoning depth and maintaining stable tool-use across 200\u2013300 sequential calls. At the same time, K2 Thinking is a native INT4 quantization model with 256k context window, achieving lossless reductions in inference latency and GPU memory usage. Key features include deep thinking & tool orchestration with end-to-end training to interleave chain-of-thought reasoning with function calls, native INT4 quantization via Quantization-Aware Training (QAT) achieving lossless 2x speed-up, and stable long-horizon agency maintaining coherent goal-directed behavior across up to 200\u2013300 consecutive tool invocations.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7-Flash\nNEW",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.7-flash",
          "origin": "CN",
          "description": "GLM-4.7-Flash is a high-speed, cost-efficient variant of GLM-4.7 optimized for fast inference and lower latency. It retains the coding-centric capabilities of GLM-4.7 including thinking before acting, preserved reasoning across turns, and per-request thinking control for speed or accuracy trade-offs. Ideal for applications requiring quick responses while maintaining strong performance on coding, agentic workflows, and general reasoning tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.5",
          "origin": "CN",
          "description": "GLM-4.5 is an Agentic, Reasoning, and Coding (ARC) foundation model designed for intelligent agents, featuring 355 billion total parameters with 32 billion active parameters using MoE architecture. Trained on 23T tokens through multi-stage training, it is a hybrid reasoning model that provides two modes: thinking mode for complex reasoning and tool usage, and non-thinking mode for immediate responses. The model unifies agentic, reasoning, and coding capabilities with 128K context length support. It achieves exceptional performance with a score of 63.2 across 12 industry-standard benchmarks, placing 3rd among all proprietary and open-source models. Released under MIT open-source license allowing commercial use and secondary development.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2 0905",
          "company": "",
          "companyLink": "https://llm-stats.com/models/kimi-k2-0905",
          "origin": "CN",
          "description": "Kimi K2 0905 is the September update of Kimi K2 0711. It is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It supports long-context inference up to 256k tokens, extended from the previous 128k. This update improves agentic coding with higher accuracy and better generalization across scaffolds, and enhances frontend coding with more aesthetic and functional outputs for web, 3D, and related tasks. The model is trained with a novel stack incorporating the MuonClip optimizer for stable large-scale MoE training.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2 (Thinking)",
          "company": "",
          "companyLink": "https://llm-stats.com/models/deepseek-reasoner",
          "origin": "CN",
          "description": "DeepSeek-V3.2 in thinking mode. A powerful reasoning model with 685B parameters using DeepSeek Sparse Attention (DSA). This mode enables extended chain-of-thought reasoning for complex problem-solving tasks. Supports JSON output and tool calls.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2026-01-21T18:22:26+08:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 0.0,
          "avgIq": 0.0,
          "avgValue": 100.0
        },
        "china": {
          "total": 0.0,
          "avgIq": 0.0,
          "avgValue": 100.0
        }
      },
      "leader": "usa",
      "models": [
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-5-20251101",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-3-pro-preview",
          "origin": "US",
          "description": "Gemini 3 Pro is the first model in the new Gemini 3 series. It is best for complex tasks that require broad world knowledge and advanced reasoning across modalities. Gemini 3 Pro uses dynamic thinking by default to reason through prompts, and features a 1 million-token input context window with 64k output tokens.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gpt-5.2-2025-12-11",
          "origin": "US",
          "description": "GPT\u20115.2 introduces substantial gains in professional knowledge work, outperforming experts on GDPval with 70.9% wins or ties, and setting new highs in coding (SWE\u2011Bench Pro 55.6%), science (GPQA Diamond ~92\u201393%), math (AIME 2025: 100%), long\u2011context accuracy up to 256k tokens, and reliable tool\u2011calling (Tau2 Telecom 98.7%). It rolls out as Instant, Thinking, and Pro\u2014faster, more structured, and less error\u2011prone\u2014priced at $1.75/1M input and $14/1M output tokens, with Pro variants supporting xhigh reasoning for top\u2011quality, end\u2011to\u2011end execution.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-3-flash-preview",
          "origin": "US",
          "description": "Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost. It combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost. Features a 1 million-token input context window and is optimized for agentic workflows, coding, and complex analysis.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-20250514",
          "origin": "US",
          "description": "Claude Opus 4 is Anthropic's most powerful model and the world's best coding model, part of the Claude 4 family. It delivers sustained performance on complex, long-running tasks and agent workflows. Opus 4 excels at coding, advanced reasoning, and can use tools (like web search) during extended thinking. It supports parallel tool execution and has improved memory capabilities.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-sonnet-4-5-20250929",
          "origin": "US",
          "description": "Claude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It\u2019s the best model at using computers. And it shows substantial gains in reasoning and math. Highest intelligence across most tasks with exceptional agent and coding capabilities.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-opus-4-1-20250805",
          "origin": "US",
          "description": "Claude Opus 4.1 is a hybrid reasoning model that pushes the frontier for coding and AI agents, featuring a 200K context window. It delivers superior performance and precision for real-world coding and agentic tasks, handling complex multi-step problems with rigor and attention to detail. With extended thinking capabilities, it offers instant responses or extended step-by-step thinking visible through user-friendly summaries. It advances state-of-the-art coding performance to 74.5% on SWE-bench Verified, excels at agentic search and research, and produces human-quality content with exceptional writing abilities. It supports 32K output tokens and adapts to specific coding styles while delivering exceptional quality for extensive generation and refactoring projects.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.1 Medium",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gpt-5.1-medium-2025-11-12",
          "origin": "US",
          "description": "GPT-5.1 Medium balances reasoning depth with response speed, providing medium-effort thinking for moderately complex tasks. This variant offers more thorough analysis than instant responses while maintaining faster performance than high-effort reasoning.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 2.5 Pro",
          "company": "",
          "companyLink": "https://llm-stats.com/models/gemini-2.5-pro",
          "origin": "US",
          "description": "A highly capable AI model from Google, designed for the agentic era. Gemini 2.5 Pro performs well on common benchmarks with enhanced reasoning, multimodal capabilities (text, image, video, audio input), and a 1M token context window.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4",
          "company": "",
          "companyLink": "https://llm-stats.com/models/claude-sonnet-4-20250514",
          "origin": "US",
          "description": "Claude Sonnet 4, part of the Claude 4 family, is a significant upgrade to Claude Sonnet 3.7. It excels in coding (72.7% on SWE-bench) and reasoning, responding more precisely to instructions. Sonnet 4 offers an optimal mix of capability and practicality, with enhanced steerability, and supports extended thinking with tool use.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.7",
          "origin": "CN",
          "description": "GLM 4.7 is a coding\u2011centric model that thinks before acting, preserves its reasoning across turns, and lets you control thinking per request for speed or accuracy. It upgrades agentic workflows with stronger multi\u2011step tool use, better terminal and multilingual coding, and a noticeable jump in UI output quality for modern, clean webpages and slides. You can use it in popular coding agents, call it via the Z.ai API, and even run it locally with public weights on HuggingFace and ModelScope using vLLM or SGLang.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.6",
          "origin": "CN",
          "description": "GLM-4.6 is the latest version of Z.ai's flagship model, bringing significant improvements over GLM-4.5. Key features include: 200K token context window (expanded from 128K), superior coding performance with better real-world application in Claude Code/Cline/Roo Code/Kilo Code, advanced reasoning with tool use during inference, stronger agent capabilities, and refined writing aligned with human preferences. GLM-4.6 achieves competitive performance with DeepSeek-V3.2-Exp and Claude Sonnet 4, reaching near parity with Claude Sonnet 4 (48.6% win rate) on CC-Bench real-world coding tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "https://llm-stats.com/models/minimax-m2.1",
          "origin": "CN",
          "description": "MiniMax M2.1 is an enhanced large language model focused on multi-language programming and real-world complex tasks. It features exceptional capabilities across Rust, Java, Golang, C++, Kotlin, Objective-C, TypeScript, JavaScript and more, with industry-leading multilingual performance that outperforms Claude Sonnet 4.5 and approaches Claude Opus 4.5. M2.1 significantly strengthens native Android and iOS development, delivers enhanced design comprehension and aesthetic expression for web/app scenarios, and provides more concise responses with improved speed and reduced token consumption. It excels across various coding agent frameworks including Claude Code, Droid (Factory AI), Cline, Kilo Code, Roo Code, and BlackBox.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2-Speciale",
          "company": "",
          "companyLink": "https://llm-stats.com/models/deepseek-v3.2-speciale",
          "origin": "CN",
          "description": "DeepSeek-V3.2-Speciale is a specialized variant of DeepSeek-V3.2, optimized for enhanced performance on specific tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "MiMo-V2-Flash",
          "company": "",
          "companyLink": "https://llm-stats.com/models/mimo-v2-flash",
          "origin": "CN",
          "description": "MiMo-V2-Flash is a powerful, efficient, and ultra-fast foundation language model that excels in reasoning, coding, and agentic scenarios. It is a Mixture-of-Experts model with 309B total parameters and 15B active parameters, featuring a hybrid attention architecture with sliding-window and full attention (5:1 ratio, 128-token window). Delivers 150 tokens/sec inference with 256k context window.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2-Thinking-0905",
          "company": "",
          "companyLink": "https://llm-stats.com/models/kimi-k2-thinking-0905",
          "origin": "CN",
          "description": "Kimi K2 Thinking is the latest, most capable version of open-source thinking model. Starting with Kimi K2, it is built as a thinking agent that reasons step-by-step while dynamically invoking tools. It sets a new state-of-the-art on Humanity's Last Exam (HLE), BrowseComp, and other benchmarks by dramatically scaling multi-step reasoning depth and maintaining stable tool-use across 200\u2013300 sequential calls. At the same time, K2 Thinking is a native INT4 quantization model with 256k context window, achieving lossless reductions in inference latency and GPU memory usage. Key features include deep thinking & tool orchestration with end-to-end training to interleave chain-of-thought reasoning with function calls, native INT4 quantization via Quantization-Aware Training (QAT) achieving lossless 2x speed-up, and stable long-horizon agency maintaining coherent goal-directed behavior across up to 200\u2013300 consecutive tool invocations.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7-Flash\nNEW",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.7-flash",
          "origin": "CN",
          "description": "GLM-4.7-Flash is a high-speed, cost-efficient variant of GLM-4.7 optimized for fast inference and lower latency. It retains the coding-centric capabilities of GLM-4.7 including thinking before acting, preserved reasoning across turns, and per-request thinking control for speed or accuracy trade-offs. Ideal for applications requiring quick responses while maintaining strong performance on coding, agentic workflows, and general reasoning tasks.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.5",
          "company": "",
          "companyLink": "https://llm-stats.com/models/glm-4.5",
          "origin": "CN",
          "description": "GLM-4.5 is an Agentic, Reasoning, and Coding (ARC) foundation model designed for intelligent agents, featuring 355 billion total parameters with 32 billion active parameters using MoE architecture. Trained on 23T tokens through multi-stage training, it is a hybrid reasoning model that provides two modes: thinking mode for complex reasoning and tool usage, and non-thinking mode for immediate responses. The model unifies agentic, reasoning, and coding capabilities with 128K context length support. It achieves exceptional performance with a score of 63.2 across 12 industry-standard benchmarks, placing 3rd among all proprietary and open-source models. Released under MIT open-source license allowing commercial use and secondary development.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2 0905",
          "company": "",
          "companyLink": "https://llm-stats.com/models/kimi-k2-0905",
          "origin": "CN",
          "description": "Kimi K2 0905 is the September update of Kimi K2 0711. It is a large-scale Mixture-of-Experts (MoE) language model developed by Moonshot AI, featuring 1 trillion total parameters with 32 billion active per forward pass. It supports long-context inference up to 256k tokens, extended from the previous 128k. This update improves agentic coding with higher accuracy and better generalization across scaffolds, and enhances frontend coding with more aesthetic and functional outputs for web, 3D, and related tasks. The model is trained with a novel stack incorporating the MuonClip optimizer for stable large-scale MoE training.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2 (Thinking)",
          "company": "",
          "companyLink": "https://llm-stats.com/models/deepseek-reasoner",
          "origin": "CN",
          "description": "DeepSeek-V3.2 in thinking mode. A powerful reasoning model with 685B parameters using DeepSeek Sparse Attention (DSA). This mode enables extended chain-of-thought reasoning for complex problem-solving tasks. Supports JSON output and tool calls.",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2026-01-21T18:12:40+08:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 212.2,
          "avgIq": 10.6,
          "avgValue": 100.0
        },
        "china": {
          "total": 276.6,
          "avgIq": 13.8,
          "avgValue": 100.0
        }
      },
      "leader": "china",
      "models": [
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2-Thinking-0905",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 60.2,
            "ARC-AGI v2": 0.0,
            "HLE": 51.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 21.1,
          "value": 100.0,
          "unified": 42.2,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "MiMo-V2-Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 94.1,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 58.3,
            "ARC-AGI v2": 0.0,
            "HLE": 22.1,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 17.4,
          "value": 100.0,
          "unified": 34.9,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2 (Thinking)",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.1,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 51.4,
            "ARC-AGI v2": 0.0,
            "HLE": 25.1,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 17.0,
          "value": 100.0,
          "unified": 33.9,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7-Flash\nNEW",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 91.6,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 42.8,
            "ARC-AGI v2": 0.0,
            "HLE": 14.4,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 14.9,
          "value": 100.0,
          "unified": 29.8,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "DeepSeek-V3.2-Speciale",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 96.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 30.6,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 12.7,
          "value": 100.0,
          "unified": 25.3,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.1 Medium",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 98.4,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 9.8,
          "value": 100.0,
          "unified": 19.7,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "Gemini 2.5 Pro",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 83.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 4.9,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.8,
          "value": 100.0,
          "unified": 17.6,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 70.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.0,
          "value": 100.0,
          "unified": 14.1,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 26.4,
            "ARC-AGI v2": 0.0,
            "HLE": 14.4,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 4.1,
          "value": 100.0,
          "unified": 8.2,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "US",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "Kimi K2 0905",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 0.0,
          "value": 100.0,
          "unified": 0.0,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2026-01-21T18:09:35+08:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 0,
          "avgIq": 0,
          "avgValue": 0
        },
        "china": {
          "total": 526.2,
          "avgIq": 13.2,
          "avgValue": 100.0
        }
      },
      "leader": "china",
      "models": [
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2026-01-21T18:01:43+08:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 0,
          "avgIq": 0,
          "avgValue": 0
        },
        "china": {
          "total": 526.2,
          "avgIq": 13.2,
          "avgValue": 100.0
        }
      },
      "leader": "china",
      "models": [
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2026-01-21T09:58:30+00:00",
      "auditDate": "Jan 21, 2026",
      "subtitle": "Performance Audit: Jan 21, 2026",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 0,
          "avgIq": 0,
          "avgValue": 0
        },
        "china": {
          "total": 526.2,
          "avgIq": 13.2,
          "avgValue": 100.0
        }
      },
      "leader": "china",
      "models": [
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 1,
          "teamBadge": ""
        },
        {
          "name": "GPT-5.2",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 52.9,
            "HLE": 34.5,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 25.3,
          "value": 100.0,
          "unified": 50.6,
          "rank": 2,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 3,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.7",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 52.0,
            "ARC-AGI v2": 0.0,
            "HLE": 42.8,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 19.1,
          "value": 100.0,
          "unified": 38.1,
          "rank": 4,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 5,
          "teamBadge": ""
        },
        {
          "name": "MiniMax M2.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 81.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 62.0,
            "ARC-AGI v2": 0.0,
            "HLE": 22.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 16.5,
          "value": 100.0,
          "unified": 33.0,
          "rank": 6,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 7,
          "teamBadge": ""
        },
        {
          "name": "GLM-4.6",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 0.0,
            "HLE": 17.2,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 15.6,
          "value": 100.0,
          "unified": 31.2,
          "rank": 8,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 9,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Flash",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 33.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.3,
          "value": 100.0,
          "unified": 26.7,
          "rank": 10,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 11,
          "teamBadge": ""
        },
        {
          "name": "Gemini 3 Pro",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 100.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 31.1,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 13.1,
          "value": 100.0,
          "unified": 26.2,
          "rank": 12,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 13,
          "teamBadge": ""
        },
        {
          "name": "Claude Sonnet 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 87.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.7,
          "value": 100.0,
          "unified": 17.4,
          "rank": 14,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 15,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 75.5,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 8.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 8.4,
          "value": 100.0,
          "unified": 16.8,
          "rank": 16,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 17,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.1",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 78.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 0.0,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 7.8,
          "value": 100.0,
          "unified": 15.6,
          "rank": 18,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 19,
          "teamBadge": ""
        },
        {
          "name": "Claude Opus 4.5",
          "company": "",
          "companyLink": "",
          "origin": "CN",
          "description": "",
          "createdDate": "",
          "costInputPer1M": 0.0,
          "costOutputPer1M": 0.0,
          "benchmarks": {
            "AIME 2025": 0.0,
            "HMMT 2025": 0.0,
            "GPQA Diamond": 0.0,
            "BrowseComp": 0.0,
            "ARC-AGI v2": 37.6,
            "HLE": 0.0,
            "MMLU-Pro": 0.0,
            "LiveCodeBench": 0.0,
            "SWE-Bench Verified": 0.0,
            "CodeForces": 0.0
          },
          "iq": 3.8,
          "value": 100.0,
          "unified": 7.5,
          "rank": 20,
          "teamBadge": ""
        }
      ]
    },
    {
      "timestamp": "2025-12-30T12:00:00-05:00",
      "auditDate": "Dec 30, 2025",
      "subtitle": "Performance Audit: Dec 30, 2025",
      "benchmarks": [
        "AIME 2025",
        "HMMT 2025",
        "GPQA Diamond",
        "BrowseComp",
        "ARC-AGI v2",
        "HLE",
        "MMLU-Pro",
        "LiveCodeBench",
        "SWE-Bench Verified",
        "CodeForces"
      ],
      "scores": {
        "usa": {
          "total": 773.3,
          "avgIq": 88.1,
          "avgValue": 75.6
        },
        "china": {
          "total": 705,
          "avgIq": 72.6,
          "avgValue": 94.5
        }
      },
      "leader": "usa",
      "models": [
        {
          "name": "Gemini 3 Flash",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google fast inference with 99.7% AIME and 90.4% GPQA. 1M context at $0.50 input.",
          "createdDate": "2025-12-16",
          "costInputPer1M": 0.5,
          "costOutputPer1M": 3,
          "benchmarks": {
            "AIME 2025": 99.7,
            "HMMT 2025": 92.1,
            "GPQA Diamond": 90.4,
            "BrowseComp": 72.3,
            "ARC-AGI v2": 80.5,
            "HLE": 36.2,
            "MMLU-Pro": 89.1,
            "LiveCodeBench": 82.4,
            "SWE-Bench Verified": 78,
            "CodeForces": 75.8
          },
          "iq": 89.4,
          "value": 86.3,
          "unified": 166.5,
          "rank": 1,
          "teamBadge": "\ud83d\udc51",
          "link": "https://llm-stats.com/models/gemini-3-flash-preview"
        },
        {
          "name": "Gemini 3 Pro",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google flagship with 91.9% GPQA and 100% AIME. 1M context. Limited benchmark coverage.",
          "createdDate": "2025-11-17",
          "costInputPer1M": 2,
          "costOutputPer1M": 12,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 93.8,
            "GPQA Diamond": 91.9,
            "BrowseComp": 74.1,
            "ARC-AGI v2": 82.3,
            "HLE": 38.5,
            "MMLU-Pro": 90.2,
            "LiveCodeBench": 83.7,
            "SWE-Bench Verified": 76.2,
            "CodeForces": 76.9
          },
          "iq": 89.4,
          "value": 73.6,
          "unified": 155.2,
          "rank": 2,
          "teamBadge": "\ud83e\udd48",
          "link": "https://llm-stats.com/models/gemini-3-pro-preview"
        },
        {
          "name": "Grok-4 Heavy",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI most powerful with 88.4% GPQA and 100% AIME. Limited benchmark coverage (3/11).",
          "createdDate": "2025-07-15",
          "costInputPer1M": 3,
          "costOutputPer1M": 15,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 90.1,
            "GPQA Diamond": 88.4,
            "BrowseComp": 68.5,
            "ARC-AGI v2": 76.2,
            "HLE": 30.4,
            "MMLU-Pro": 88.6,
            "LiveCodeBench": 79.4,
            "SWE-Bench Verified": 71.8,
            "CodeForces": 73.2
          },
          "iq": 89.3,
          "value": 71,
          "unified": 152.7,
          "rank": 3,
          "teamBadge": "\ud83e\udd49",
          "link": "https://llm-stats.com/models/grok-4-heavy"
        },
        {
          "name": "GPT-5.1",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI model with 88.1% GPQA and 94% AIME. Limited to 3/10 benchmarks.",
          "createdDate": "2025-11-12",
          "costInputPer1M": 1.25,
          "costOutputPer1M": 10,
          "benchmarks": {
            "AIME 2025": 94,
            "HMMT 2025": 88.5,
            "GPQA Diamond": 88.1,
            "BrowseComp": 65.3,
            "ARC-AGI v2": 74.1,
            "HLE": 34.7,
            "MMLU-Pro": 87.9,
            "LiveCodeBench": 77.2,
            "SWE-Bench Verified": 76.3,
            "CodeForces": 72.1
          },
          "iq": 86.1,
          "value": 76.1,
          "unified": 151.7,
          "rank": 4,
          "teamBadge": "\u2b50",
          "link": "https://llm-stats.com/models/gpt-5.1-2025-11-13"
        },
        {
          "name": "Grok-4",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI flagship with 87.5% GPQA and 79% LiveCodeBench. Limited benchmark coverage (3/11).",
          "createdDate": "2025-07-08",
          "costInputPer1M": 3,
          "costOutputPer1M": 15,
          "benchmarks": {
            "AIME 2025": 91.7,
            "HMMT 2025": 85.2,
            "GPQA Diamond": 87.5,
            "BrowseComp": 62.1,
            "ARC-AGI v2": 71.8,
            "HLE": 28.3,
            "MMLU-Pro": 87.4,
            "LiveCodeBench": 79,
            "SWE-Bench Verified": 72.9,
            "CodeForces": 71.4
          },
          "iq": 86.1,
          "value": 71,
          "unified": 147.2,
          "rank": 5,
          "teamBadge": "\u2b50",
          "link": "https://llm-stats.com/models/grok-4"
        },
        {
          "name": "DeepSeek-V3.2-Exp",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek experimental variant with 70.7% CodeForces and extended 164K context.",
          "createdDate": "2025-09-28",
          "costInputPer1M": 0.27,
          "costOutputPer1M": 0.41,
          "benchmarks": {
            "AIME 2025": 89.3,
            "HMMT 2025": 84.7,
            "GPQA Diamond": 79.9,
            "BrowseComp": 40.1,
            "ARC-AGI v2": 68.3,
            "HLE": 19.8,
            "MMLU-Pro": 85,
            "LiveCodeBench": 74.1,
            "SWE-Bench Verified": 67.8,
            "CodeForces": 70.7
          },
          "iq": 72.4,
          "value": 98.2,
          "unified": 143.5,
          "rank": 6,
          "teamBadge": "\ud83d\udc51",
          "link": "https://llm-stats.com/models/deepseek-v3.2-exp"
        },
        {
          "name": "Kimi K2-Thinking",
          "company": "Moonshot AI",
          "companyLink": "https://www.moonshot.cn/",
          "origin": "CN",
          "description": "Moonshot reasoning model with highest HLE score (51%). 100% AIME 2025. Extended thinking for complex problems.",
          "createdDate": "2025-12-05",
          "costInputPer1M": 0.47,
          "costOutputPer1M": 2,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 96.1,
            "GPQA Diamond": 84.5,
            "BrowseComp": 60.2,
            "ARC-AGI v2": 79.7,
            "HLE": 51,
            "MMLU-Pro": 84.6,
            "LiveCodeBench": 76.8,
            "SWE-Bench Verified": 71.3,
            "CodeForces": 68.4
          },
          "iq": 75.3,
          "value": 88.8,
          "unified": 142.1,
          "rank": 7,
          "teamBadge": "\u2b50",
          "link": "https://llm-stats.com/models/kimi-k2-thinking-0905"
        },
        {
          "name": "DeepSeek-V3.2 (Thinking)",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek V3.2 thinking model with extended reasoning capabilities. Strong performance across coding, math, and reasoning benchmarks with improved cost efficiency.",
          "createdDate": "2025-12-20",
          "costInputPer1M": 0.27,
          "costOutputPer1M": 0.41,
          "benchmarks": {
            "AIME 2025": 93.3,
            "HMMT 2025": 91.2,
            "GPQA Diamond": 82.8,
            "BrowseComp": 52.1,
            "ARC-AGI v2": 75.4,
            "HLE": 28.3,
            "MMLU-Pro": 85.2,
            "LiveCodeBench": 84.1,
            "SWE-Bench Verified": 74.3,
            "CodeForces": 80.2
          },
          "iq": 74.8,
          "value": 98.2,
          "unified": 147.5,
          "rank": 8,
          "teamBadge": "\ud83e\udd48",
          "link": "https://llm-stats.com/models/deepseek-reasoner"
        },
        {
          "name": "Qwen3-235B-Thinking",
          "company": "Alibaba Cloud",
          "companyLink": "https://www.alibabacloud.com/",
          "origin": "CN",
          "description": "Alibaba Qwen3 with only model to have ARC-AGI data (41.8%) among Chinese models.",
          "createdDate": "2025-11-28",
          "costInputPer1M": 0.3,
          "costOutputPer1M": 3,
          "benchmarks": {
            "AIME 2025": 92.3,
            "HMMT 2025": 89.4,
            "GPQA Diamond": 81.1,
            "BrowseComp": 48.7,
            "ARC-AGI v2": 72.1,
            "HLE": 25.6,
            "MMLU-Pro": 84.4,
            "LiveCodeBench": 70.7,
            "SWE-Bench Verified": 68.9,
            "CodeForces": 65.3
          },
          "iq": 74.1,
          "value": 87.6,
          "unified": 138.9,
          "rank": 9,
          "teamBadge": "\u2b50",
          "link": "https://llm-stats.com/models/qwen3-235b-a22b-thinking-2507"
        },
        {
          "name": "MiMo-V2-Flash",
          "company": "Xiaomi",
          "companyLink": "https://www.mi.com/",
          "origin": "CN",
          "description": "Xiaomi efficient model with 6/10 benchmarks covered. 256K context at ultra-low $0.10 input.",
          "createdDate": "2025-12-08",
          "costInputPer1M": 0.1,
          "costOutputPer1M": 0.3,
          "benchmarks": {
            "AIME 2025": 94.1,
            "HMMT 2025": 87.3,
            "GPQA Diamond": 83.7,
            "BrowseComp": 58.3,
            "ARC-AGI v2": 69.4,
            "HLE": 22.1,
            "MMLU-Pro": 84.9,
            "LiveCodeBench": 75.2,
            "SWE-Bench Verified": 73.4,
            "CodeForces": 62.8
          },
          "iq": 69.4,
          "value": 100,
          "unified": 138.8,
          "rank": 10,
          "teamBadge": "\ud83e\udd49",
          "link": "https://llm-stats.com/models/mimo-v2-flash"
        },
        {
          "name": "Gemini 2.5 Pro Preview",
          "company": "Google DeepMind",
          "companyLink": "https://deepmind.google/",
          "origin": "US",
          "description": "Google preview with 86.4% GPQA and 88% AIME. 4/10 benchmarks covered.",
          "createdDate": "2025-06-05",
          "costInputPer1M": 1.25,
          "costOutputPer1M": 10,
          "benchmarks": {
            "AIME 2025": 88,
            "HMMT 2025": 82.3,
            "GPQA Diamond": 86.4,
            "BrowseComp": 58.9,
            "ARC-AGI v2": 75.1,
            "HLE": 31.8,
            "MMLU-Pro": 83.7,
            "LiveCodeBench": 69,
            "SWE-Bench Verified": 67.2,
            "CodeForces": 64.5
          },
          "iq": 77.7,
          "value": 76.1,
          "unified": 136.7,
          "rank": 11,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gemini-2-5-pro-preview"
        },
        {
          "name": "Claude Opus 4.5",
          "company": "Anthropic",
          "companyLink": "https://www.anthropic.com/",
          "origin": "US",
          "description": "Anthropic flagship with 80.9% SWE-Bench. Constitutional AI. Very limited benchmark data (3/11).",
          "createdDate": "2025-11-23",
          "costInputPer1M": 5,
          "costOutputPer1M": 25,
          "benchmarks": {
            "AIME 2025": 79.3,
            "HMMT 2025": 75.4,
            "GPQA Diamond": 87,
            "BrowseComp": 51.2,
            "ARC-AGI v2": 70.9,
            "HLE": 44.2,
            "MMLU-Pro": 77.6,
            "LiveCodeBench": 73.5,
            "SWE-Bench Verified": 80.9,
            "CodeForces": 62.1
          },
          "iq": 81.8,
          "value": 66.3,
          "unified": 136.1,
          "rank": 12,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/claude-opus-4-5-20251101"
        },
        {
          "name": "GLM-4.7",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI with 42.8% HLE (2nd highest) and 95.7% AIME. Strong multilingual capabilities.",
          "createdDate": "2025-12-18",
          "costInputPer1M": 0.6,
          "costOutputPer1M": 2.2,
          "benchmarks": {
            "AIME 2025": 95.7,
            "HMMT 2025": 91.2,
            "GPQA Diamond": 85.7,
            "BrowseComp": 52,
            "ARC-AGI v2": 73.4,
            "HLE": 42.8,
            "MMLU-Pro": 84.3,
            "LiveCodeBench": 77.1,
            "SWE-Bench Verified": 73.8,
            "CodeForces": 69.7
          },
          "iq": 72.4,
          "value": 87.4,
          "unified": 135.6,
          "rank": 13,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4-7"
        },
        {
          "name": "GPT-5.2",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI flagship with 86.2% ARC-AGI and highest raw benchmark scores. Limited benchmark coverage hurts IQ.",
          "createdDate": "2025-12-10",
          "costInputPer1M": 1.75,
          "costOutputPer1M": 14,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 97.5,
            "GPQA Diamond": 92.4,
            "BrowseComp": 65.8,
            "ARC-AGI v2": 86.2,
            "HLE": 34.5,
            "MMLU-Pro": 88.9,
            "LiveCodeBench": 81.7,
            "SWE-Bench Verified": 80,
            "CodeForces": 77.3
          },
          "iq": 76.5,
          "value": 73,
          "unified": 132.3,
          "rank": 14,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gpt-5.2"
        },
        {
          "name": "MiniMax M2.1",
          "company": "MiniMax",
          "companyLink": "https://www.minimaxi.com/",
          "origin": "CN",
          "description": "MiniMax flagship with highest MMLU-Pro (88%). 1M context with strong Chinese language processing.",
          "createdDate": "2025-12-22",
          "costInputPer1M": 0.3,
          "costOutputPer1M": 1.2,
          "benchmarks": {
            "AIME 2025": 81,
            "HMMT 2025": 77.2,
            "GPQA Diamond": 81,
            "BrowseComp": 62,
            "ARC-AGI v2": 64.8,
            "HLE": 22,
            "MMLU-Pro": 88,
            "LiveCodeBench": 78,
            "SWE-Bench Verified": 67,
            "CodeForces": 59.2
          },
          "iq": 68.4,
          "value": 93.2,
          "unified": 132.2,
          "rank": 15,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/minimax-m2.1"
        },
        {
          "name": "Grok 4 Fast",
          "company": "xAI",
          "companyLink": "https://x.ai/",
          "origin": "US",
          "description": "xAI ultra-efficient with 80% LiveCodeBench and 92% AIME. 2M context at just $0.20 input.",
          "createdDate": "2025-12-15",
          "costInputPer1M": 0.2,
          "costOutputPer1M": 0.5,
          "benchmarks": {
            "AIME 2025": 92,
            "HMMT 2025": 86.7,
            "GPQA Diamond": 85.7,
            "BrowseComp": 44.9,
            "ARC-AGI v2": 68.5,
            "HLE": 20,
            "MMLU-Pro": 83.4,
            "LiveCodeBench": 80,
            "SWE-Bench Verified": 72.1,
            "CodeForces": 66.9
          },
          "iq": 64.5,
          "value": 99.1,
          "unified": 128.5,
          "rank": 16,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/grok-4-fast"
        },
        {
          "name": "GPT-5.2 Pro",
          "company": "OpenAI",
          "companyLink": "https://openai.com/",
          "origin": "US",
          "description": "OpenAI highest-intelligence with 93.2% GPQA (best) and 90.5% ARC-AGI. Premium pricing at $21 input.",
          "createdDate": "2025-12-11",
          "costInputPer1M": 21,
          "costOutputPer1M": 168,
          "benchmarks": {
            "AIME 2025": 100,
            "HMMT 2025": 98.2,
            "GPQA Diamond": 93.2,
            "BrowseComp": 77.9,
            "ARC-AGI v2": 90.5,
            "HLE": 36.6,
            "MMLU-Pro": 91.2,
            "LiveCodeBench": 84.3,
            "SWE-Bench Verified": 82.7,
            "CodeForces": 79.8
          },
          "iq": 79.6,
          "value": 50.3,
          "unified": 119.7,
          "rank": 17,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/gpt-5.2-pro"
        },
        {
          "name": "DeepSeek-R1-0528",
          "company": "DeepSeek",
          "companyLink": "https://www.deepseek.com/",
          "origin": "CN",
          "description": "DeepSeek reasoning model with 64.3% CodeForces. Strong math and reasoning at $0.50 input.",
          "createdDate": "2025-12-01",
          "costInputPer1M": 0.5,
          "costOutputPer1M": 2.15,
          "benchmarks": {
            "AIME 2025": 87.5,
            "HMMT 2025": 81.8,
            "GPQA Diamond": 81,
            "BrowseComp": 8.9,
            "ARC-AGI v2": 62.3,
            "HLE": 15.7,
            "MMLU-Pro": 85,
            "LiveCodeBench": 73.3,
            "SWE-Bench Verified": 44.6,
            "CodeForces": 64.3
          },
          "iq": 63.5,
          "value": 88.2,
          "unified": 119.5,
          "rank": 18,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/deepseek-r1-0528"
        },
        {
          "name": "GLM-4.6",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI mid-tier with 93.9% AIME 2025 and 68% SWE-Bench. Strong Chinese language capabilities.",
          "createdDate": "2025-11-20",
          "costInputPer1M": 0.55,
          "costOutputPer1M": 2.19,
          "benchmarks": {
            "AIME 2025": 93.9,
            "HMMT 2025": 89.3,
            "GPQA Diamond": 81,
            "BrowseComp": 45.1,
            "ARC-AGI v2": 66.7,
            "HLE": 17.2,
            "MMLU-Pro": 79.8,
            "LiveCodeBench": 71.4,
            "SWE-Bench Verified": 68,
            "CodeForces": 58.6
          },
          "iq": 61,
          "value": 87.7,
          "unified": 114.6,
          "rank": 19,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4.6"
        },
        {
          "name": "GLM-4.5",
          "company": "Zhipu AI",
          "companyLink": "https://www.zhipuai.cn/",
          "origin": "CN",
          "description": "Zhipu AI efficient model with 84.6% MMLU-Pro and 72.9% LiveCodeBench at $0.40 input.",
          "createdDate": "2025-11-15",
          "costInputPer1M": 0.4,
          "costOutputPer1M": 1.6,
          "benchmarks": {
            "AIME 2025": 78.5,
            "HMMT 2025": 73.2,
            "GPQA Diamond": 79.1,
            "BrowseComp": 26.4,
            "ARC-AGI v2": 58.9,
            "HLE": 14.4,
            "MMLU-Pro": 84.6,
            "LiveCodeBench": 72.9,
            "SWE-Bench Verified": 64.2,
            "CodeForces": 52.1
          },
          "iq": 56.9,
          "value": 90.6,
          "unified": 108.5,
          "rank": 20,
          "teamBadge": "",
          "link": "https://llm-stats.com/models/glm-4.5"
        }
      ]
    }
  ]
}